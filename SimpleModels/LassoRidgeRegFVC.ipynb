{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneOut, KFold , train_test_split \n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading npy data.\n",
    "X = np.load(\"/VS dir/PlayingSpiroData/Spiro-Data/npy_file/FVC_FEATURES_60.npy\")\n",
    "y = np.load(\"/VS dir/PlayingSpiroData/Spiro-Data/npy_file/FVC_LABELS_60.npy\")\n",
    "\n",
    "# Removing erroreneous data\n",
    "\n",
    "X= pd.DataFrame(X).drop(index=[23,55,4,9,52,44,45,33,43,20,1,50])\n",
    "y= pd.DataFrame(y).drop(index=[23,55,4,9,52,44,45,33,43,20,1,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\n",
      "Ridge Regressor for FEV1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\tMean Absolute Percentage Error :  7.183423054993867\n",
      "\tMean Aabsolute Error :  0.23664864769821906\n",
      "\tMean Square Error :  0.10812562490568306\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ls = Ridge(alpha=1)\n",
    "\n",
    "# Total number of the splits\n",
    "tot = len(X)\n",
    "# Instantiating Leave_One_Out split function.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "prog = 0\n",
    "y_GT = []\n",
    "y_PT = []\n",
    "abserror=[]\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\")\n",
    "print(\"Ridge Regressor for FEV1\")\n",
    "\n",
    "# For every split obtained by Leave_One_Out split function.\n",
    "for i,(train_index, test_index) in enumerate(loo.split(X)):\n",
    "    \n",
    "    # To show some sort of progress.\n",
    "    prog = prog + 1\n",
    "    print(\"Progress : {0}/{1}\".format(prog,tot),end = '\\r')\n",
    "\n",
    "    # Test-train split for the fold.\n",
    "    X_Tr, X_T = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_Tr, y_T = y.iloc[train_index],y.iloc[test_index]\n",
    "    \n",
    "    # Training new Random Forest ensemble.\n",
    "    Ls.fit(X_Tr, np.ravel(y_Tr))\n",
    "    pred = Ls.predict(X_T)  \n",
    "\n",
    "    # Storing the values of Ground truth and Predicted value for future use.\n",
    "    y_GT.append(y_T.iloc[0,0])\n",
    "    y_PT.append(pred[0]) \n",
    "\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_GT,y_PT))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_GT,y_PT))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_GT,y_PT))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\n",
      "Lasso Regressor for FEV1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\tMean Absolute Percentage Error :  7.320819194907145\n",
      "\tMean Aabsolute Error :  0.24123226950354623\n",
      "\tMean Square Error :  0.11045971027614303\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Ls = Lasso(alpha=1)\n",
    "\n",
    "\n",
    "# Total number of the splits\n",
    "tot = len(X)\n",
    "# Instantiating Leave_One_Out split function.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "prog = 0\n",
    "y_GT = []\n",
    "y_PT = []\n",
    "abserror=[]\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\")\n",
    "print(\"Lasso Regressor for FEV1\")\n",
    "\n",
    "# For every split obtained by Leave_One_Out split function.\n",
    "for i,(train_index, test_index) in enumerate(loo.split(X)):\n",
    "    \n",
    "    # To show some sort of progress.\n",
    "    prog = prog + 1\n",
    "    print(\"Progress : {0}/{1}\".format(prog,tot),end = '\\r')\n",
    "\n",
    "    # Test-train split for the fold.\n",
    "    X_Tr, X_T = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_Tr, y_T = y.iloc[train_index],y.iloc[test_index]\n",
    "    \n",
    "    # Training new Random Forest ensemble.\n",
    "    Ls.fit(X_Tr, np.ravel(y_Tr))\n",
    "    pred = Ls.predict(X_T)  \n",
    "\n",
    "    # Storing the values of Ground truth and Predicted value for future use.\n",
    "    y_GT.append(y_T.iloc[0,0])\n",
    "    y_PT.append(pred[0]) \n",
    "\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_GT,y_PT))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_GT,y_PT))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_GT,y_PT))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f6a27bcfbe46a917dbd192f4a82657396dda26148bae633192e8d28c70725f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
