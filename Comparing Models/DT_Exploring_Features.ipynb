{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,mean_absolute_error\n",
    "from sklearn.model_selection import LeaveOneOut, KFold , train_test_split \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Analysis for FEV1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading npy data.\n",
    "X = np.load(\"/VS dir/PlayingSpiroData/Spiro-Data/npy_file/FEV1_FEATURES_60.npy\")\n",
    "y = np.load(\"/VS dir/PlayingSpiroData/Spiro-Data/npy_file/FEV1_LABELS_60.npy\")\n",
    "\n",
    "# Removing erroreneous data\n",
    "\n",
    "X= pd.DataFrame(X).drop(index=[23,55,4,9,52,44,45,33,43,20,1,50])\n",
    "y= pd.DataFrame(y).drop(index=[23,55,4,9,52,44,45,33,43,20,1,50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Decision tree and identifying feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval indexes are :  [5, 6, 8, 11, 12, 15, 16, 18, 19, 21, 24, 29, 30, 31, 32, 35, 38, 39, 46, 48, 49, 54, 57, 58]\n",
      "work indexes are :  [0, 2, 3, 7, 10, 13, 14, 17, 22, 25, 26, 27, 28, 34, 36, 37, 40, 41, 42, 47, 51, 53, 56, 59]\n",
      "Inportant feature obtained [0, 1, 3, 6, 8, 23, 77, 81, 97, 111]\n"
     ]
    }
   ],
   "source": [
    "# Instantiating Decision Tree Regressor.\n",
    "DT = DecisionTreeRegressor( criterion='squared_error',min_samples_leaf=1, \n",
    "                                min_samples_split=5,random_state=42)\n",
    "\n",
    "X_work,X_eval,y_work,y_eval = train_test_split(X,y,test_size=0.5,shuffle=True,random_state=42)\n",
    "\n",
    "print(\"Eval indexes are : \",list(X_eval.index.sort_values()))\n",
    "print(\"work indexes are : \",list(X_work.index.sort_values()))\n",
    "\n",
    "DT.fit(X_eval,y_eval)\n",
    "\n",
    "DT_imp = pd.DataFrame(DT.feature_importances_)\n",
    "feature_index = list(DT_imp[DT_imp[0]>0].index)\n",
    "\n",
    "print(\"Inportant feature obtained\",feature_index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining Random Forest using Leave one out Cross Validation using new features and using entire work-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\n",
      "Random Forest Regressor for FEV1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Random forest metrics with reduced feature set\n",
      "\tMean Absolute Percentage Error :  8.562313597380369\n",
      "\tMean Aabsolute Error :  0.25345118433418395\n",
      "\tMean Square Error :  0.11717913390428775\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
     ]
    }
   ],
   "source": [
    "X_new = X_work.iloc[:,feature_index]\n",
    "y_new = y_work\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X_new,y_new,test_size=0.5,shuffle=True,random_state=42)\n",
    "\n",
    "RF_new = RandomForestRegressor( n_jobs=-1, bootstrap=True, criterion='squared_error', \n",
    "                                  n_estimators=500,  max_features='sqrt', max_depth=100,  \n",
    "                                  min_samples_leaf=1, min_samples_split=5 ,random_state=42)\n",
    "\n",
    "# Total number of the splits\n",
    "tot = len(X_new)\n",
    "# Instantiating Leave_One_Out split function.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "prog = 0\n",
    "y_GT = []\n",
    "y_PT = []\n",
    "abserror=[]\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\")\n",
    "print(\"Random Forest Regressor for FEV1\")\n",
    "\n",
    "# For every split obtained by Leave_One_Out split function.\n",
    "for i,(train_index, test_index) in enumerate(loo.split(X_new)):\n",
    "    \n",
    "    # To show some sort of progress.\n",
    "    prog = prog + 1\n",
    "    print(\"Progress : {0}/{1}\".format(prog,tot),end = '\\r')\n",
    "\n",
    "    # Test-train split for the fold.\n",
    "    X_Tr, X_T = X_new.iloc[train_index],X_new.iloc[test_index]\n",
    "    y_Tr, y_T = y_new.iloc[train_index],y_new.iloc[test_index]\n",
    "    \n",
    "    # Training new Random Forest ensemble.\n",
    "    RF_new.fit(X_Tr, np.ravel(y_Tr))\n",
    "    pred = RF_new.predict(X_T)  \n",
    "\n",
    "    # Storing the values of Ground truth and Predicted value for future use.\n",
    "    y_GT.append(y_T.iloc[0,0])\n",
    "    y_PT.append(pred[0]) \n",
    "\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"Random forest metrics with reduced feature set\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_GT,y_PT))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_GT,y_PT))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_GT,y_PT))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor for FEV1 on the 70-30 holdout set\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Random forest metrics with reduced feature set\n",
      "\tMean Absolute Percentage Error :  4.714133809140775\n",
      "\tMean Aabsolute Error :  0.12617502857142612\n",
      "\tMean Square Error :  0.04282827381633935\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = X_work.iloc[:,feature_index]\n",
    "y_new = y_work\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_new,y_new,train_size=0.8,shuffle=True,random_state=42)\n",
    "\n",
    "RF_new = RandomForestRegressor( n_jobs=-1, bootstrap=True, criterion='squared_error', \n",
    "                                  n_estimators=500,  max_features='sqrt', max_depth=100,  \n",
    "                                  min_samples_leaf=1, min_samples_split=5 ,random_state=42)\n",
    "\n",
    "\n",
    "RF_new.fit(X_train,np.ravel(y_train))\n",
    "y_hat = RF_new.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor for FEV1 on the 70-30 holdout set\")\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"Random forest metrics with reduced feature set\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_test,y_hat))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_test,y_hat))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_test,y_hat))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor for FEV1 on the entire y set\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Random forest metrics with reduced feature set\n",
      "\tMean Absolute Percentage Error :  4.760528542193643\n",
      "\tMean Aabsolute Error :  0.14218146957671943\n",
      "\tMean Square Error :  0.03381261279138157\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = RF_new.predict(X.iloc[:,feature_index])\n",
    "\n",
    "print(\"Random Forest Regressor for FEV1 on the entire y set\")\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"Random forest metrics with reduced feature set\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y,y_hat))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y,y_hat))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y,y_hat))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining Random Forest using Leave one out Cross Validation using new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\n",
      "Random Forest Regressor for FEV1 using LOOCV\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Random forest metrics with reduced feature set\n",
      "\tMean Absolute Percentage Error :  12.381338887059174\n",
      "\tMean Aabsolute Error :  0.36560647091450205\n",
      "\tMean Square Error :  0.17860589558381984\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "Random Forest Regressor for FEV1 on the holdout set\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "Random forest metrics with reduced feature set\n",
      "\tMean Absolute Percentage Error :  5.107618940365664\n",
      "\tMean Aabsolute Error :  0.1405352602813848\n",
      "\tMean Square Error :  0.035503002116922366\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = X_work.iloc[:,feature_index]\n",
    "y_new = y_work\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_new,y_new,test_size=0.3,shuffle=True,random_state=42)\n",
    "\n",
    "RF_new = RandomForestRegressor( n_jobs=-1, bootstrap=True, criterion='squared_error', \n",
    "                                  n_estimators=500,  max_features='sqrt', max_depth=100,  \n",
    "                                  min_samples_leaf=1, min_samples_split=5 ,random_state=42)\n",
    "\n",
    "# Total number of the splits\n",
    "tot = len(X_train)\n",
    "# Instantiating Leave_One_Out split function.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "prog = 0\n",
    "y_GT = []\n",
    "y_PT = []\n",
    "abserror=[]\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=\")\n",
    "print(\"Random Forest Regressor for FEV1 using LOOCV\")\n",
    "\n",
    "# For every split obtained by Leave_One_Out split function.\n",
    "for i,(train_index, test_index) in enumerate(loo.split(X_train)):\n",
    "    \n",
    "    # To show some sort of progress.\n",
    "    prog = prog + 1\n",
    "    print(\"Progress : {0}/{1}\".format(prog,tot),end = '\\r')\n",
    "\n",
    "    # Test-train split for the fold.\n",
    "    X_Tr, X_T = X_train.iloc[train_index],X_train.iloc[test_index]\n",
    "    y_Tr, y_T = y_train.iloc[train_index],y_train.iloc[test_index]\n",
    "    \n",
    "    # Training new Random Forest ensemble.\n",
    "    RF_new.fit(X_Tr, np.ravel(y_Tr))\n",
    "    pred = RF_new.predict(X_T)  \n",
    "\n",
    "    # Storing the values of Ground truth and Predicted value for future use.\n",
    "    y_GT.append(y_T.iloc[0,0])\n",
    "    y_PT.append(pred[0]) \n",
    "\n",
    "\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"Random forest metrics with reduced feature set\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_GT,y_PT))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_GT,y_PT))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_GT,y_PT))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n\")\n",
    "\n",
    "\n",
    "print(\"Random Forest Regressor for FEV1 on the holdout set\")\n",
    "RF_new.fit(X_train, np.ravel(y_train))\n",
    "y_hat = RF_new.predict(X_test)\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\")\n",
    "print(\"Random forest metrics with reduced feature set\")\n",
    "print(\"\\tMean Absolute Percentage Error : \" , 100 * mean_absolute_percentage_error(y_test,y_hat))\n",
    "print(\"\\tMean Aabsolute Error : \" , mean_absolute_error(y_test,y_hat))\n",
    "print(\"\\tMean Square Error : \" , mean_squared_error(y_test,y_hat))\n",
    "print(\"=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f6a27bcfbe46a917dbd192f4a82657396dda26148bae633192e8d28c70725f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
